{"cells":[{"cell_type":"code","source":["!pip install wfdb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJQ-D_ODb5VP","executionInfo":{"status":"ok","timestamp":1736824306545,"user_tz":-540,"elapsed":3851,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"fe5c8464-369c-4abf-bb11-4067907f6697"},"id":"wJQ-D_ODb5VP","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wfdb\n","  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.13.0)\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.10.0)\n","Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.26.4)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.2.2)\n","Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.32.3)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2024.12.14)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n","Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: wfdb\n","Successfully installed wfdb-4.1.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1yypUKvoybh","executionInfo":{"status":"ok","timestamp":1736824334070,"user_tz":-540,"elapsed":25079,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"084fc542-2654-4235-d717-055912aba2c6"},"id":"W1yypUKvoybh","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"id":"c340bafe-2b47-47b9-9cbb-b4c90e0e6f48","metadata":{"id":"c340bafe-2b47-47b9-9cbb-b4c90e0e6f48","executionInfo":{"status":"ok","timestamp":1736821692151,"user_tz":-540,"elapsed":626,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# ptb-xl load"]},{"cell_type":"code","execution_count":3,"id":"21e497e1-fa2d-4b17-8721-b6a7fd6c4876","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21e497e1-fa2d-4b17-8721-b6a7fd6c4876","executionInfo":{"status":"ok","timestamp":1736824348300,"user_tz":-540,"elapsed":10972,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"9e3cfaf9-6483-4b4f-9fe8-685a29b12a27"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x78815f114370>"]},"metadata":{},"execution_count":3}],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import wfdb\n","import ast\n","import sys\n","import os\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MultipleLocator\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import _LRScheduler\n","from torch.utils.data import DataLoader, Dataset\n","from einops.layers.torch import Rearrange\n","import time\n","import pickle\n","from random import randint\n","from scipy import signal\n","from tqdm import tqdm\n","\n","path = '/content/drive/MyDrive/Colab Notebooks'\n","sys.path.append(path)\n","from ECGDataset_1D import ECGDataset_1D\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","torch.manual_seed(0)"]},{"cell_type":"code","execution_count":4,"id":"f754bb11-68c6-4062-9ef7-20bd5871b631","metadata":{"id":"f754bb11-68c6-4062-9ef7-20bd5871b631","executionInfo":{"status":"ok","timestamp":1736824352150,"user_tz":-540,"elapsed":514,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["sampling_rate=100 # or 500\n","\n","n_batch = 64\n","n_workers = 0\n","\n","num_classes = 4"]},{"cell_type":"code","execution_count":7,"id":"08cd3aa4-46e0-48a9-bb2b-9e6275676b71","metadata":{"id":"08cd3aa4-46e0-48a9-bb2b-9e6275676b71","executionInfo":{"status":"ok","timestamp":1736821722964,"user_tz":-540,"elapsed":607,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def load_raw_data(df, sampling_rate, path):\n","    if sampling_rate == 100:\n","        data = [wfdb.rdsamp(os.path.join(path,f)) for f in df.filename_lr]\n","    else:\n","        data = [wfdb.rdsamp(os.path.join(path,f)) for f in df.filename_hr]\n","    data = np.array([signal for signal, meta in data])\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"8d716862-3380-4006-ae85-347ba6a8c3e2","metadata":{"id":"8d716862-3380-4006-ae85-347ba6a8c3e2"},"outputs":[],"source":["def aggregate_diagnostic(y_dic):\n","    tmp = []\n","    for key in y_dic.keys():\n","        if key in agg_df.index:\n","            tmp.append(agg_df.loc[key].diagnostic_class)\n","    return list(set(tmp))"]},{"cell_type":"code","execution_count":null,"id":"abe42fd8-5ade-42dd-9217-f1dcc638e8e9","metadata":{"id":"abe42fd8-5ade-42dd-9217-f1dcc638e8e9"},"outputs":[],"source":["def ECG_signal2image(sig_data, idx):\n","    row = [None] * 4\n","    sample = sig_data[idx]\n","    height = 2\n","    plt.figure(figsize = (50,30))\n","    f = plt.subplot(111)\n","\n","    for i in range(3):\n","        row[i] = np.concatenate([sample[i+3*j][j*250:(j+1)*250] for j in range(4)]) - i * 2 * height\n","        plt.plot(row[i], color='black')\n","    row[3] = sample[1] - 6 * height\n","    plt.plot(row[3], color='black')\n","\n","    plt.ylim([-7*height,height])\n","\n","    f.xaxis.set_major_locator(MultipleLocator(20))\n","    f.xaxis.set_minor_locator(MultipleLocator(4))\n","    f.yaxis.set_major_locator(MultipleLocator(0.5))\n","    f.yaxis.set_minor_locator(MultipleLocator(0.1))\n","\n","    f.xaxis.grid(True,'minor', color='r', linewidth=1)\n","    f.xaxis.grid(True,'major', color='r', linewidth=2)\n","    f.yaxis.grid(True,'minor', color='r', linewidth=1)\n","    f.yaxis.grid(True,'major', color='r', linewidth=2)\n","\n","    f.xaxis.set_tick_params(labelbottom=False)\n","    f.yaxis.set_tick_params(labelleft=False)\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0cb51e6a-c9ec-43d2-90cb-f02375ef2221","metadata":{"id":"0cb51e6a-c9ec-43d2-90cb-f02375ef2221"},"outputs":[],"source":["def df2one_hot_superclass_tensor(diag_data):\n","    diag_superclass = ['MI', 'STTC', 'CD', 'HYP']\n","\n","    data_len = len(diag_data)\n","    label_train = torch.zeros((data_len,4))\n","\n","    re_y = diag_data.reset_index().diagnostic_superclass\n","\n","    for i in range(data_len):\n","        for diag in re_y[i]:\n","            for j in range(4):\n","                if diag == diag_superclass[j]:\n","                    label_train[i][j] = 1\n","\n","    return label_train"]},{"cell_type":"code","execution_count":5,"id":"c0d255ad-1108-435a-9634-7484556ba168","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0d255ad-1108-435a-9634-7484556ba168","executionInfo":{"status":"ok","timestamp":1736824377800,"user_tz":-540,"elapsed":20903,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"60a7db78-5f4c-4889-e957-7b9b96f1ae81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded\n"]}],"source":["try:\n","    with open(os.path.join(path,'train','train_dataset.pickle'),\"rb\") as f:\n","        train_dataset = pickle.load(f)\n","    with open(os.path.join(path,'train','test_dataset.pickle'),\"rb\") as f:\n","        test_dataset = pickle.load(f)\n","\n","    print(\"Dataset loaded\")\n","\n","except:\n","    print(\"Error with opening pickle\")\n","    print(\"Making new pickle\")\n","\n","    Y = pd.read_csv(os.path.join(path,'ptbxl_database.csv'), index_col='ecg_id')\n","    Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n","\n","    # Load raw signal data\n","    X = load_raw_data(Y, sampling_rate, path).transpose(0,2,1) # (len,1000,12) -> (len,12,1000)\n","\n","    # Load scp_statements.csv for diagnostic aggregation\n","    agg_df = pd.read_csv(os.path.join(path,'scp_statements.csv'), index_col=0)\n","    agg_df = agg_df[agg_df.diagnostic == 1]\n","\n","    # Apply diagnostic superclass\n","    Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n","\n","    # Split data into train and test\n","    test_fold = 10\n","    # Train\n","    X_train = X[np.where(Y.strat_fold != test_fold)]\n","    y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n","    # Test\n","    X_test = X[np.where(Y.strat_fold == test_fold)]\n","    y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass\n","\n","    train_dataset = ECGDataset_1D(torch.tensor(X_train), df2one_hot_superclass_tensor(y_train))\n","    test_dataset = ECGDataset_1D(torch.tensor(X_test), df2one_hot_superclass_tensor(y_test))\n","\n","    with open(os.path.join(path,'train','train_dataset.pickle'),\"wb\") as f:\n","        pickle.dump(train_dataset,f)\n","    with open(os.path.join(path,'train','test_dataset.pickle'),\"wb\") as f:\n","        pickle.dump(test_dataset,f)\n","\n","    print(\"New pickle saved and loaded\")"]},{"cell_type":"code","execution_count":6,"id":"1f2657b1-80e1-4e83-b7f8-2a312288ab56","metadata":{"id":"1f2657b1-80e1-4e83-b7f8-2a312288ab56","executionInfo":{"status":"ok","timestamp":1736824383030,"user_tz":-540,"elapsed":569,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=n_batch, shuffle=True, num_workers=n_workers, pin_memory=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=n_batch, shuffle=True, num_workers=n_workers, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"id":"f911a05b-beee-49ad-8590-b21b45e6293f","metadata":{"id":"f911a05b-beee-49ad-8590-b21b45e6293f"},"outputs":[],"source":["# SOTA simple Model\n","# https://github.com/cph-cachet/LocalLeadAttention"]},{"cell_type":"code","execution_count":7,"id":"f498e346-cb41-4ec7-a6db-359f46838226","metadata":{"id":"f498e346-cb41-4ec7-a6db-359f46838226","executionInfo":{"status":"ok","timestamp":1736824386671,"user_tz":-540,"elapsed":625,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class DepthWiseSeparableConvBlock(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        out_channels,\n","        kernel_size,\n","        stride = 1,\n","        padding = 0,\n","        dilation = 1,\n","        bias = True,\n","        padding_mode = 'zeros',\n","        inner_kernel_size = 1,\n","        inner_stride = 1,\n","        inner_padding = 0\n","    ):\n","        super(DepthWiseSeparableConvBlock, self).__init__()\n","        self.depth_wise_conv = nn.Conv2d(\n","            in_channels=in_channels, out_channels=out_channels,\n","            kernel_size=(1, kernel_size), stride=(1, stride), padding=(0, padding),\n","            dilation=(1, dilation), groups=in_channels, bias=bias, padding_mode=padding_mode)\n","\n","        self.non_linearity = nn.LeakyReLU()\n","\n","        self.batch_norm = nn.BatchNorm2d(out_channels)\n","\n","        self.point_wise = nn.Conv2d(\n","            in_channels=out_channels, out_channels=out_channels,\n","            kernel_size=(1, inner_kernel_size), stride=(1, inner_stride), padding=(0, inner_padding),\n","            dilation=1, groups=1, bias=bias, padding_mode=padding_mode)\n","\n","    def forward(self, x):\n","        x = self.depth_wise_conv(x)\n","        x = self.non_linearity(x)\n","        x = self.batch_norm(x)\n","        x = self.point_wise(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":8,"id":"5e5dcd4c-4fac-41f7-81a9-e337e2c6b61d","metadata":{"id":"5e5dcd4c-4fac-41f7-81a9-e337e2c6b61d","executionInfo":{"status":"ok","timestamp":1736824387757,"user_tz":-540,"elapsed":5,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride, depth):\n","        super(Block, self).__init__()\n","        assert out_channels % in_channels == 0\n","\n","        self.p0 = DepthWiseSeparableConvBlock(in_channels, out_channels, kernel_size=9, stride=1)\n","\n","        self.p01 = DepthWiseSeparableConvBlock(out_channels, out_channels, kernel_size=9, stride=stride)\n","\n","        self.p1 = nn.ModuleList()\n","        for _ in range(depth):\n","            self.p1.append(DepthWiseSeparableConvBlock(out_channels, out_channels, kernel_size=9, stride=1, padding=4))\n","        self.p1 = nn.Sequential(*self.p1)\n","\n","    def forward(self, x):\n","        x = self.p0(x)\n","        x = self.p01(x)\n","        res = x\n","\n","        x = self.p1(x)\n","        x = res + x\n","\n","        return x"]},{"cell_type":"code","execution_count":9,"id":"b7e45f4a-bf65-4f0f-a4d3-6cccef8679c4","metadata":{"id":"b7e45f4a-bf65-4f0f-a4d3-6cccef8679c4","executionInfo":{"status":"ok","timestamp":1736824388331,"user_tz":-540,"elapsed":4,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class LocalMaskedMHCA(nn.Module):\n","    \"\"\"\n","    Local Multi Head Conv Attention with mask\n","\n","    Add a depthwise convolution within a standard MHA\n","    The extra conv op can be used to\n","    (1) encode relative position information (relacing position encoding);\n","    (2) downsample the features if needed;\n","    (3) match the feature channels\n","\n","    Note: With current implementation, the downsampled feature will be aligned\n","    to every s+1 time step, where s is the downsampling stride. This allows us\n","    to easily interpolate the corresponding positional embeddings.\n","\n","    The implementation is fairly tricky, code reference from\n","    https://github.com/huggingface/transformers/blob/master/src/transformers/models/longformer/modeling_longformer.py\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        n_embd,          # dimension of the output features\n","        n_head,          # number of heads in multi-head self-attention\n","        window_size,     # size of the local attention window\n","        n_stride=1,      # dowsampling stride for query, key, value and input\n","        attn_pdrop=0.0,  # dropout rate for the attention map\n","        proj_pdrop=0.0  # dropout rate for projection op\n","    ):\n","        super().__init__()\n","        assert n_embd % n_head == 0\n","        assert (n_stride == 1) or (n_stride % 2 == 0)\n","        assert window_size > 1 and n_head >= 1\n","        self.n_head = n_head\n","        self.n_channels = n_embd // n_head\n","        self.scale = 1.0 / math.sqrt(self.n_channels)\n","        self.window_overlap = window_size // 2\n","        # must use an odd window size\n","\n","        # query, key, value conv (depthwise)\n","        kernel_size = n_stride + 1 if n_stride > 1 else 3\n","        padding = kernel_size // 2\n","\n","        self.query_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.query_norm = nn.BatchNorm2d(n_embd)\n","\n","        self.key_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.key_norm = nn.BatchNorm2d(n_embd)\n","\n","        self.value_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.value_norm = nn.BatchNorm2d(n_embd)\n","\n","        # key, query, value projections for all heads\n","        # it is OK to ignore masking, as the mask will be attached on the attention\n","        self.key = nn.Conv2d(n_embd, n_embd, 1)\n","        self.query = nn.Conv2d(n_embd, n_embd, 1)\n","        self.value = nn.Conv2d(n_embd, n_embd, 1)\n","\n","        # regularization\n","        self.attn_drop = nn.Dropout(attn_pdrop)\n","        self.proj_drop = nn.Dropout(proj_pdrop)\n","\n","        # output projection\n","        self.proj = nn.Conv2d(n_embd, n_embd, 1)\n","\n","    @staticmethod\n","    def _chunk(x, window_overlap):\n","        \"\"\"convert into overlapping chunks. Chunk size = 2w, overlap size = w\"\"\"\n","        # x: B x nh, T, hs\n","        # non-overlapping chunks of size = 2w -> B x nh, T//2w, 2w, hs\n","        x = x.view(\n","            x.size(0),\n","            x.size(1) // (window_overlap * 2),\n","            window_overlap * 2,\n","            x.size(2),\n","        )\n","\n","        # use `as_strided` to make the chunks overlap with an overlap size = window_overlap\n","        chunk_size = list(x.size())\n","        chunk_size[1] = chunk_size[1] * 2 - 1\n","        chunk_stride = list(x.stride())\n","        chunk_stride[1] = chunk_stride[1] // 2\n","\n","        # B x nh, #chunks = T//w - 1, 2w, hs\n","        return x.as_strided(size=chunk_size, stride=chunk_stride)\n","\n","    @staticmethod\n","    def _pad_and_transpose_last_two_dims(x, padding):\n","        \"\"\"pads rows and then flips rows and columns\"\"\"\n","        # padding value is not important because it will be overwritten\n","        x = nn.functional.pad(x, padding)\n","        x = x.view(*x.size()[:-2], x.size(-1), x.size(-2))\n","        return x\n","\n","    @staticmethod\n","    def _mask_invalid_locations(input_tensor, affected_seq_len):\n","        beginning_mask_2d = input_tensor.new_ones(\n","            affected_seq_len, affected_seq_len + 1).tril().flip(dims=[0])\n","        beginning_mask = beginning_mask_2d[None, :, None, :]\n","        ending_mask = beginning_mask.flip(dims=(1, 3))\n","        beginning_input = input_tensor[:,\n","                                       :affected_seq_len, :, : affected_seq_len + 1]\n","        beginning_mask = beginning_mask.expand(beginning_input.size())\n","        # `== 1` converts to bool or uint8\n","        beginning_input.masked_fill_(beginning_mask == 1, -float(\"inf\"))\n","        ending_input = input_tensor[:, -\n","                                    affected_seq_len:, :, -(affected_seq_len + 1):]\n","        ending_mask = ending_mask.expand(ending_input.size())\n","        # `== 1` converts to bool or uint8\n","        ending_input.masked_fill_(ending_mask == 1, -float(\"inf\"))\n","\n","    @staticmethod\n","    def _pad_and_diagonalize(x):\n","        \"\"\"\n","        shift every row 1 step right, converting columns into diagonals.\n","        Example::\n","              chunked_hidden_states: [ 0.4983,  2.6918, -0.0071,  1.0492,\n","                                       -1.8348,  0.7672,  0.2986,  0.0285,\n","                                       -0.7584,  0.4206, -0.0405,  0.1599,\n","                                       2.0514, -1.1600,  0.5372,  0.2629 ]\n","              window_overlap = num_rows = 4\n","             (pad & diagonalize) =>\n","             [ 0.4983,  2.6918, -0.0071,  1.0492, 0.0000,  0.0000,  0.0000\n","               0.0000,  -1.8348,  0.7672,  0.2986,  0.0285, 0.0000,  0.0000\n","               0.0000,  0.0000, -0.7584,  0.4206, -0.0405,  0.1599, 0.0000\n","               0.0000,  0.0000,  0.0000, 2.0514, -1.1600,  0.5372,  0.2629 ]\n","        \"\"\"\n","        total_num_heads, num_chunks, window_overlap, hidden_dim = x.size()\n","        # total_num_heads x num_chunks x window_overlap x (hidden_dim+window_overlap+1).\n","        x = nn.functional.pad(\n","            x, (0, window_overlap + 1)\n","        )\n","        # total_num_heads x num_chunks x window_overlap*window_overlap+window_overlap\n","        x = x.view(total_num_heads, num_chunks, -1)\n","        # total_num_heads x num_chunks x window_overlap*window_overlap\n","        x = x[:, :, :-window_overlap]\n","        x = x.view(\n","            total_num_heads, num_chunks, window_overlap, window_overlap + hidden_dim\n","        )\n","        x = x[:, :, :, :-1]\n","        return x\n","\n","    def _sliding_chunks_query_key_matmul(\n","        self, query, key, num_heads, window_overlap\n","    ):\n","        \"\"\"\n","        Matrix multiplication of query and key tensors using with a sliding window attention pattern. This implementation splits the input into overlapping chunks of size 2w with an overlap of size w (window_overlap)\n","        \"\"\"\n","        # query / key: B*nh, T, hs\n","        bnh, seq_len, head_dim = query.size()\n","        batch_size = bnh // num_heads\n","        assert seq_len % (window_overlap * 2) == 0\n","        assert query.size() == key.size()\n","\n","        chunks_count = seq_len // window_overlap - 1\n","\n","        # B * num_heads, head_dim, #chunks=(T//w - 1), 2w\n","        chunk_query = self._chunk(query, window_overlap)\n","        chunk_key = self._chunk(key, window_overlap)\n","\n","        # matrix multiplication\n","        # bcxd: batch_size * num_heads x chunks x 2window_overlap x head_dim\n","        # bcyd: batch_size * num_heads x chunks x 2window_overlap x head_dim\n","        # bcxy: batch_size * num_heads x chunks x 2window_overlap x 2window_overlap\n","        diagonal_chunked_attention_scores = torch.einsum(\n","            \"bcxd,bcyd->bcxy\", (chunk_query, chunk_key))\n","\n","        # convert diagonals into columns\n","        # B * num_heads, #chunks, 2w, 2w+1\n","        diagonal_chunked_attention_scores = self._pad_and_transpose_last_two_dims(\n","            diagonal_chunked_attention_scores, padding=(0, 0, 0, 1)\n","        )\n","\n","        # allocate space for the overall attention matrix where the chunks are combined. The last dimension\n","        # has (window_overlap * 2 + 1) columns. The first (window_overlap) columns are the window_overlap lower triangles (attention from a word to\n","        # window_overlap previous words). The following column is attention score from each word to itself, then\n","        # followed by window_overlap columns for the upper triangle.\n","        diagonal_attention_scores = diagonal_chunked_attention_scores.new_empty(\n","            (batch_size * num_heads, chunks_count + 1,\n","             window_overlap, window_overlap * 2 + 1)\n","        )\n","\n","        # copy parts from diagonal_chunked_attention_scores into the combined matrix of attentions\n","        # - copying the main diagonal and the upper triangle\n","        diagonal_attention_scores[:, :-1, :, window_overlap:] = diagonal_chunked_attention_scores[\n","            :, :, :window_overlap, : window_overlap + 1\n","        ]\n","        diagonal_attention_scores[:, -1, :, window_overlap:] = diagonal_chunked_attention_scores[\n","            :, -1, window_overlap:, : window_overlap + 1\n","        ]\n","        # - copying the lower triangle\n","        diagonal_attention_scores[:, 1:, :, :window_overlap] = diagonal_chunked_attention_scores[\n","            :, :, -(window_overlap + 1): -1, window_overlap + 1:\n","        ]\n","\n","        diagonal_attention_scores[:, 0, 1:window_overlap, 1:window_overlap] = diagonal_chunked_attention_scores[\n","            :, 0, : window_overlap - 1, 1 - window_overlap:\n","        ]\n","\n","        # separate batch_size and num_heads dimensions again\n","        diagonal_attention_scores = diagonal_attention_scores.view(\n","            batch_size, num_heads, seq_len, 2 * window_overlap + 1\n","        ).transpose(2, 1)\n","\n","        self._mask_invalid_locations(diagonal_attention_scores, window_overlap)\n","        return diagonal_attention_scores\n","\n","    def _sliding_chunks_matmul_attn_probs_value(\n","        self, attn_probs, value, num_heads, window_overlap\n","    ):\n","        \"\"\"\n","        Same as _sliding_chunks_query_key_matmul but for attn_probs and value tensors. Returned tensor will be of the\n","        same shape as `attn_probs`\n","        \"\"\"\n","        bnh, seq_len, head_dim = value.size()\n","        batch_size = bnh // num_heads\n","        assert seq_len % (window_overlap * 2) == 0\n","        assert attn_probs.size(3) == 2 * window_overlap + 1\n","        chunks_count = seq_len // window_overlap - 1\n","        # group batch_size and num_heads dimensions into one, then chunk seq_len into chunks of size 2 window overlap\n","\n","        chunked_attn_probs = attn_probs.transpose(1, 2).reshape(\n","            batch_size * num_heads, seq_len // window_overlap, window_overlap, 2 * window_overlap + 1\n","        )\n","\n","        # pad seq_len with w at the beginning of the sequence and another window overlap at the end\n","        padded_value = nn.functional.pad(\n","            value, (0, 0, window_overlap, window_overlap), value=-1)\n","\n","        # chunk padded_value into chunks of size 3 window overlap and an overlap of size window overlap\n","        chunked_value_size = (batch_size * num_heads,\n","                              chunks_count + 1, 3 * window_overlap, head_dim)\n","        chunked_value_stride = padded_value.stride()\n","        chunked_value_stride = (\n","            chunked_value_stride[0],\n","            window_overlap * chunked_value_stride[1],\n","            chunked_value_stride[1],\n","            chunked_value_stride[2],\n","        )\n","        chunked_value = padded_value.as_strided(\n","            size=chunked_value_size, stride=chunked_value_stride)\n","\n","        chunked_attn_probs = self._pad_and_diagonalize(chunked_attn_probs)\n","\n","        context = torch.einsum(\n","            \"bcwd,bcdh->bcwh\", (chunked_attn_probs, chunked_value))\n","        return context.view(batch_size, num_heads, seq_len, head_dim)\n","\n","    def forward(self, x):\n","        # x: batch size, feature channel, sequence length,\n","        # mask: batch size, 1, sequence length (bool)\n","        B, C, L, T = x.size()\n","\n","        # x = x.permute(0, 2, 1, 3)\n","       # print('asf.',x.shape)\n","\n","        # step 1: depth convolutions\n","        # query, key, value conv -> (B, nh * hs, T)\n","        q = self.query_conv(x)\n","        q = self.query_norm(q)\n","        k = self.key_conv(x)\n","        k = self.key_norm(k)\n","        v = self.value_conv(x)\n","        v = self.value_norm(v)\n","\n","        # step 2: query, key, value transforms & reshape\n","        # projections\n","        q = self.query(q)\n","        k = self.key(k)\n","        v = self.value(v)\n","\n","        # x = x.permute(0, 2, 1, 3)\n","        # (B, nh * hs, T) -> (B, nh, T, hs)\n","        q = q.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).contiguous()\n","        k = k.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).contiguous()\n","        v = v.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).contiguous()\n","        # view as (B * nh, T, hs)\n","        q = q.view(B * self.n_head, -1, self.n_channels*L).contiguous()\n","        k = k.view(B * self.n_head, -1, self.n_channels*L).contiguous()\n","        v = v.view(B * self.n_head, -1, self.n_channels*L).contiguous()\n","\n","        # step 3: compute local self-attention with rel pe and masking\n","        q *= self.scale\n","        # chunked query key attention -> B, T, nh, 2w+1 = window_size\n","        att = self._sliding_chunks_query_key_matmul(q, k, self.n_head, self.window_overlap)\n","\n","        # ignore input masking for now\n","        att = F.softmax(att, dim=-1)\n","        # softmax sometimes inserts NaN if all positions are masked, replace\n","        att = self.attn_drop(att)\n","\n","        # step 4: compute attention value product + output projection\n","        # chunked attn value product -> B, nh, T, hs\n","        out = self._sliding_chunks_matmul_attn_probs_value(att, v, self.n_head, self.window_overlap)\n","        # transpose to B, nh, hs, T -> B, nh*hs, T\n","        out = out.transpose(2, 3).contiguous().view(B, C, L, -1)\n","        # output projection + skip connection\n","        out = self.proj_drop(self.proj(out))\n","\n","        return out"]},{"cell_type":"code","execution_count":10,"id":"f798f2fe-f66b-4fa3-a6bc-7e26d6cb571b","metadata":{"id":"f798f2fe-f66b-4fa3-a6bc-7e26d6cb571b","executionInfo":{"status":"ok","timestamp":1736824389017,"user_tz":-540,"elapsed":5,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class MaskedMHCA(nn.Module):\n","\n","    def __init__(\n","        self,\n","        n_embd,          # dimension of the output features\n","        n_head,          # number of heads in multi-head self-attention\n","        n_stride=1,      # dowsampling stride for query, key, value and input\n","        attn_pdrop=0.0,  # dropout rate for the attention map\n","        proj_pdrop=0.0  # dropout rate for projection op\n","    ):\n","        super().__init__()\n","        assert n_embd % n_head == 0\n","        assert (n_stride == 1) or (n_stride % 2 == 0)\n","        self.n_head = n_head\n","        self.n_channels = n_embd // n_head\n","        self.scale = 1.0 / math.sqrt(self.n_channels)\n","\n","        # query, key, value conv (depthwise)\n","        kernel_size = n_stride + 1 if n_stride > 1 else 3\n","        padding = kernel_size // 2\n","\n","        self.query_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.query_norm = nn.BatchNorm2d(n_embd)\n","\n","        self.key_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.key_norm = nn.BatchNorm2d(n_embd)\n","\n","        self.value_conv = nn.Conv2d(\n","            n_embd, n_embd, (1, kernel_size),\n","            stride=(1, n_stride), padding=(0, padding), groups=n_embd, bias=False\n","        )\n","        self.value_norm = nn.BatchNorm2d(n_embd)\n","\n","        # key, query, value projections for all heads\n","        # it is OK to ignore masking, as the mask will be attached on the attention\n","        self.key = nn.Conv2d(n_embd, n_embd, 1)\n","        self.query = nn.Conv2d(n_embd, n_embd, 1)\n","        self.value = nn.Conv2d(n_embd, n_embd, 1)\n","\n","        # regularization\n","        self.attn_drop = nn.Dropout(attn_pdrop)\n","        self.proj_drop = nn.Dropout(proj_pdrop)\n","\n","        # output projection\n","        self.proj = nn.Conv2d(n_embd, n_embd, 1)\n","\n","    def forward(self, x):\n","        # x: batch size, feature channel, sequence length,\n","        # mask: batch size, 1, sequence length (bool)\n","        B, C, L, T = x.size()\n","\n","        # query, key, value conv -> (B, nh * hs, T)\n","        q = self.query_conv(x)\n","        q = self.query_norm(q)\n","        k = self.key_conv(x)\n","        k = self.key_norm(k)\n","        v = self.value_conv(x)\n","        v = self.value_norm(v)\n","\n","        # projections\n","        q = self.query(q)\n","        k = self.key(k)\n","        v = self.value(v)\n","\n","        # move head forward to be the batch dim\n","        # (B, nh * hs, T) -> (B, nh, T, hs)\n","        k = k.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).flatten(-2)\n","        q = q.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).flatten(-2)\n","        v = v.view(B, self.n_head, self.n_channels, L, -1).transpose(2, 4).flatten(-2)\n","\n","        # self-attention: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        att = (q * self.scale) @ k.transpose(-2, -1)\n","\n","        # softmax attn\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_drop(att)\n","        # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        out = att @ v\n","        # re-assemble all head outputs side by side\n","        out = out.transpose(2, 3).contiguous().view(B, C, L, -1)\n","\n","        # output projection + skip connection\n","        out = self.proj_drop(self.proj(out))\n","\n","        return out"]},{"cell_type":"code","execution_count":11,"id":"31966708-7b64-4807-b4b0-73a0b7f7c198","metadata":{"id":"31966708-7b64-4807-b4b0-73a0b7f7c198","executionInfo":{"status":"ok","timestamp":1736824389017,"user_tz":-540,"elapsed":4,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","    \"\"\"\n","    A simple (post layer norm) Transformer block\n","    Modified from https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        n_embd,                # dimension of the input features\n","        n_head,                # number of attention heads\n","        n_stride=1,        # downsampling strides for q & x, k & v\n","        n_out=None,            # output dimension, if None, set to input dim\n","        n_hidden=None,         # dimension of the hidden layer in MLP\n","        attn_pdrop=0.0,        # dropout rate for the attention map\n","        proj_pdrop=0.0,        # dropout rate for the projection / MLP\n","        path_pdrop=0.0,        # drop path rate\n","        mha_win_size=-1,       # > 0 to use window mha\n","    ):\n","        super().__init__()\n","        # layer norm for order (B C T)\n","        self.ln1 = nn.BatchNorm2d(n_embd)\n","        self.ln2 = nn.BatchNorm2d(n_embd)\n","\n","        # specify the attention module\n","        if mha_win_size > 1:\n","            self.attn = LocalMaskedMHCA(\n","                n_embd,\n","                n_head,\n","                window_size=mha_win_size,\n","                n_stride=n_stride,\n","                attn_pdrop=attn_pdrop,\n","                proj_pdrop=proj_pdrop\n","            )\n","        else:\n","            self.attn = MaskedMHCA(\n","                n_embd,\n","                n_head,\n","                n_stride=n_stride,\n","                attn_pdrop=attn_pdrop,\n","                proj_pdrop=proj_pdrop\n","            )\n","\n","        # input\n","        if n_stride > 1:\n","            kernel_size = n_stride + 1\n","            padding = kernel_size // 2\n","            self.pool_skip = nn.MaxPool2d((1, kernel_size), stride=(1, n_stride), padding=(0, padding))\n","        else:\n","            self.pool_skip = nn.Identity()\n","\n","        # two layer mlp\n","        n_hidden = 4 * n_embd  # default\n","        n_out = n_embd\n","        # ok to use conv1d here with stride=1\n","        self.mlp = nn.Sequential(\n","            nn.Conv2d(n_embd, n_hidden, 1),\n","            nn.GELU(),\n","            nn.Dropout(proj_pdrop, inplace=True),\n","            nn.Conv2d(n_hidden, n_out, 1),\n","            nn.Dropout(proj_pdrop, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        # pre-LN transformer: https://arxiv.org/pdf/2002.04745.pdf\n","        out = self.attn(self.ln1(x))\n","        out = out + self.pool_skip(x)\n","        # FFN\n","        out = out + self.mlp(self.ln2(out))\n","\n","        return out"]},{"cell_type":"code","execution_count":12,"id":"5c454d94-76c3-49ed-b750-3153c4ed2239","metadata":{"id":"5c454d94-76c3-49ed-b750-3153c4ed2239","executionInfo":{"status":"ok","timestamp":1736824389601,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class ConvTransformerBackbone(nn.Module):\n","    \"\"\"\n","        A backbone that combines convolutions with transformers\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        n_in,                  # input feature dimension\n","        n_embd,                # embedding dimension (after convolution)\n","        n_head,                # number of head for self-attention in transformers\n","        n_embd_ks,             # conv kernel size of the embedding network\n","        arch=(2, 2, 8),      # (#convs, #stem transformers, #branch transformers)\n","        mha_win_size=[-1]*9,  # size of local window for mha\n","        scale_factor=2,      # dowsampling rate for the branch\n","        attn_pdrop=0.0,      # dropout rate for the attention map\n","        proj_pdrop=0.0,      # dropout rate for the projection / MLP\n","        path_pdrop=0.1,      # droput rate for drop path\n","    ):\n","        super().__init__()\n","        assert len(arch) == 3\n","        assert len(mha_win_size) == (1 + arch[2])\n","        self.arch = arch\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # embedding network using convs\n","        self.embd = nn.ModuleList()\n","        self.embd_norm = nn.ModuleList()\n","        for idx in range(arch[0]):\n","            embd_in = n_embd if idx > 0 else n_in\n","            self.embd.append(\n","                nn.Conv2d(\n","                    embd_in, n_embd, (1, n_embd_ks),\n","                    stride=(1, 1), padding=(0, n_embd_ks//2), bias=False\n","                )\n","            )\n","            self.embd_norm.append(nn.BatchNorm2d(n_embd))\n","\n","        # stem network using (vanilla) transformer\n","        self.stem = nn.ModuleList()\n","        for idx in range(arch[1]):\n","            self.stem.append(\n","                TransformerBlock(\n","                    n_embd, n_head,\n","                    n_stride=1,\n","                    attn_pdrop=attn_pdrop,\n","                    proj_pdrop=proj_pdrop,\n","                    path_pdrop=path_pdrop,\n","                    mha_win_size=mha_win_size[0]\n","                )\n","            )\n","\n","        # main branch using transformer with pooling\n","        self.branch = nn.ModuleList()\n","        for idx in range(arch[2]):\n","            self.branch.append(\n","                TransformerBlock(\n","                    n_embd, n_head,\n","                    n_stride=scale_factor,\n","                    attn_pdrop=attn_pdrop,\n","                    proj_pdrop=proj_pdrop,\n","                    path_pdrop=path_pdrop,\n","                    mha_win_size=mha_win_size[1 + idx]\n","                )\n","            )\n","\n","        # init weights\n","        self.apply(self.__init_weights__)\n","\n","    def __init_weights__(self, module):\n","        # set nn.Linear/nn.Conv1d bias term to 0\n","        if isinstance(module, (nn.Linear, nn.Conv1d)):\n","            if module.bias is not None:\n","                torch.nn.init.constant_(module.bias, 0.)\n","\n","    def forward(self, x):\n","        # x: batch size, feature channel, sequence length,\n","        # mask: batch size, 1, sequence length (bool)\n","        #B, C, L, T = x.size()\n","\n","        # feature projection\n","        for idx in range(self.arch[0]):\n","            x = self.embd[idx](x)\n","            x = self.relu(self.embd_norm[idx](x))\n","\n","        # stem transformer\n","        for idx in range(self.arch[1]):\n","            x = self.stem[idx](x)\n","\n","        # main branch with downsampling\n","        for idx in range(self.arch[2]):\n","            x = self.branch[idx](x)\n","\n","        return x"]},{"cell_type":"code","execution_count":13,"id":"9d99869c-c4b8-4a18-ad33-23014d0281fb","metadata":{"id":"9d99869c-c4b8-4a18-ad33-23014d0281fb","executionInfo":{"status":"ok","timestamp":1736824390150,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["class FinalModel(nn.Module):\n","    def __init__(self, num_classes=26):\n","        super(FinalModel, self).__init__()\n","        self.num_classes = num_classes\n","\n","        self.blocks = nn.Sequential(\n","            Block(1, 24, 2, 4),\n","            Block(24, 48, 2, 5),\n","            Block(48, 96, 2, 6),\n","            Block(96, 96, 1, 7),\n","            nn.Conv2d(96, 128, kernel_size=1))\n","\n","        self.embd_dim = 128\n","        self.transformer = ConvTransformerBackbone(n_in=128,\n","                                                   n_embd=self.embd_dim,\n","                                                   n_head=4,\n","                                                   n_embd_ks=5,\n","                                                   arch=(2, 2, 8),\n","                                                   mha_win_size=[19]*6 + [-1]*3)\n","        self.linearN = nn.Sequential(nn.Linear(60, 32),\n","                                     nn.ReLU(),\n","                                     nn.Linear(32, 1))\n","        self.linear1 = nn.Linear(self.embd_dim, 128)\n","        self.linear2 = nn.Linear(128, self.num_classes)\n","\n","    def forward(self, x):\n","        x = self.blocks(x.transpose(1,2))\n","        x = F.interpolate(x, size=(12, 1152), mode='bilinear')\n","\n","        x = self.transformer(x)\n","        x = F.leaky_relu(self.linearN(x.flatten(-2)).squeeze(-1))\n","\n","        x = F.leaky_relu(self.linear1(x))\n","        x = self.linear2(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":17,"id":"f6a7b4fd-500f-4ea2-ab06-b37014c828f4","metadata":{"id":"f6a7b4fd-500f-4ea2-ab06-b37014c828f4","executionInfo":{"status":"ok","timestamp":1736821786761,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# Training"]},{"cell_type":"code","execution_count":14,"id":"def4ac82-cc8d-438a-abc7-17e14ff766ff","metadata":{"id":"def4ac82-cc8d-438a-abc7-17e14ff766ff","executionInfo":{"status":"ok","timestamp":1736824394340,"user_tz":-540,"elapsed":613,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# ASL Loss\n","#https://github.com/Alibaba-MIIL/ASL/tree/main\n","#Asymmetric Loss For Multi-Label Classification\n","class AsymmetricLossOptimized(nn.Module):\n","    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n","    favors inplace operations'''\n","\n","    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n","        super(AsymmetricLossOptimized, self).__init__()\n","\n","        self.gamma_neg = gamma_neg\n","        self.gamma_pos = gamma_pos\n","        self.clip = clip\n","        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n","        self.eps = eps\n","\n","        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n","        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n","\n","    def forward(self, x, y):\n","        \"\"\"\"\n","        Parameters\n","        ----------\n","        x: input logits\n","        y: targets (multi-label binarized vector)\n","        \"\"\"\n","\n","        self.targets = y\n","        self.anti_targets = 1 - y\n","\n","        # Calculating Probabilities\n","        self.xs_pos = torch.sigmoid(x)\n","        self.xs_neg = 1.0 - self.xs_pos\n","\n","        # Asymmetric Clipping\n","        if self.clip is not None and self.clip > 0:\n","            self.xs_neg.add_(self.clip).clamp_(max=1)\n","\n","        # Basic CE calculation\n","        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n","        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n","\n","        # Asymmetric Focusing\n","        if self.gamma_neg > 0 or self.gamma_pos > 0:\n","            if self.disable_torch_grad_focal_loss:\n","                torch.set_grad_enabled(False)\n","            self.xs_pos = self.xs_pos * self.targets\n","            self.xs_neg = self.xs_neg * self.anti_targets\n","            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n","                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n","            if self.disable_torch_grad_focal_loss:\n","                torch.set_grad_enabled(True)\n","            self.loss *= self.asymmetric_w\n","\n","        return -self.loss.sum()"]},{"cell_type":"code","execution_count":15,"id":"321b723c-7f46-44e1-b691-f66fb67d8887","metadata":{"id":"321b723c-7f46-44e1-b691-f66fb67d8887","executionInfo":{"status":"ok","timestamp":1736824394899,"user_tz":-540,"elapsed":2,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# Cosine Annealing Warmup Restarts\n","#https://gaussian37.github.io/dl-pytorch-lr_scheduler/\n","#https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup/tree/master\n","class CosineAnnealingWarmupRestarts(_LRScheduler):\n","    \"\"\"\n","        optimizer (Optimizer): Wrapped optimizer.\n","        first_cycle_steps (int): First cycle step size.\n","        cycle_mult(float): Cycle steps magnification. Default: -1.\n","        max_lr(float): First cycle's max learning rate. Default: 0.1.\n","        min_lr(float): Min learning rate. Default: 0.001.\n","        warmup_steps(int): Linear warmup step size. Default: 0.\n","        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n","        last_epoch (int): The index of last epoch. Default: -1.\n","    \"\"\"\n","\n","    def __init__(self,\n","                 optimizer : torch.optim.Optimizer,\n","                 first_cycle_steps : int,\n","                 cycle_mult : float = 1.,\n","                 max_lr : float = 0.1,\n","                 min_lr : float = 0.001,\n","                 warmup_steps : int = 0,\n","                 gamma : float = 1.,\n","                 last_epoch : int = -1\n","        ):\n","        assert warmup_steps < first_cycle_steps\n","\n","        self.first_cycle_steps = first_cycle_steps # first cycle step size\n","        self.cycle_mult = cycle_mult # cycle steps magnification\n","        self.base_max_lr = max_lr # first max learning rate\n","        self.max_lr = max_lr # max learning rate in the current cycle\n","        self.min_lr = min_lr # min learning rate\n","        self.warmup_steps = warmup_steps # warmup step size\n","        self.gamma = gamma # decrease rate of max learning rate by cycle\n","\n","        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n","        self.cycle = 0 # cycle count\n","        self.step_in_cycle = last_epoch # step size of the current cycle\n","\n","        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n","\n","        # set learning rate min_lr\n","        self.init_lr()\n","\n","    def init_lr(self):\n","        self.base_lrs = []\n","        for param_group in self.optimizer.param_groups:\n","            param_group['lr'] = self.min_lr\n","            self.base_lrs.append(self.min_lr)\n","\n","    def get_lr(self):\n","        if self.step_in_cycle == -1:\n","            return self.base_lrs\n","        elif self.step_in_cycle < self.warmup_steps:\n","            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n","        else:\n","            return [base_lr + (self.max_lr - base_lr) \\\n","                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n","                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n","                    for base_lr in self.base_lrs]\n","\n","    def step(self, epoch=None):\n","        if epoch is None:\n","            epoch = self.last_epoch + 1\n","            self.step_in_cycle = self.step_in_cycle + 1\n","            if self.step_in_cycle >= self.cur_cycle_steps:\n","                self.cycle += 1\n","                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n","                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n","        else:\n","            if epoch >= self.first_cycle_steps:\n","                if self.cycle_mult == 1.:\n","                    self.step_in_cycle = epoch % self.first_cycle_steps\n","                    self.cycle = epoch // self.first_cycle_steps\n","                else:\n","                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n","                    self.cycle = n\n","                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n","                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n","            else:\n","                self.cur_cycle_steps = self.first_cycle_steps\n","                self.step_in_cycle = epoch\n","\n","        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n","        self.last_epoch = math.floor(epoch)\n","        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n","            param_group['lr'] = lr"]},{"cell_type":"code","execution_count":16,"id":"65ebf13f-3a43-4b73-bd0a-5026648a71c3","metadata":{"id":"65ebf13f-3a43-4b73-bd0a-5026648a71c3","executionInfo":{"status":"ok","timestamp":1736824396617,"user_tz":-540,"elapsed":519,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["model = FinalModel(num_classes).to(device)"]},{"cell_type":"code","execution_count":17,"id":"0bf93360-5c3e-4055-a61c-12db7ba25f60","metadata":{"id":"0bf93360-5c3e-4055-a61c-12db7ba25f60","executionInfo":{"status":"ok","timestamp":1736824396617,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# ASL criterion constants\n","gamma_neg = 0.2\n","gamma_pos = 0\n","clip = 0 # 0.05\n","eps = 1e-8\n","\n","criterion = AsymmetricLossOptimized(gamma_neg, gamma_pos, clip, eps)"]},{"cell_type":"code","execution_count":29,"id":"943fc3fb-676f-45ea-953b-3f935903d877","metadata":{"id":"943fc3fb-676f-45ea-953b-3f935903d877","executionInfo":{"status":"ok","timestamp":1736824607337,"user_tz":-540,"elapsed":4,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["# cosine annealing warm restart scheduler constants\n","first_cycle_steps = 10000      #first_cycle_steps (int): First cycle step size\n","cycle_mult = 1.0            #cycle_mult(float): Cycle steps magnification. Default: -1.0\n","max_lr = 3e-4               #max_lr(float): First cycle's max learning rate. Default: 0.1\n","min_lr = 1e-5               #min_lr(float): Min learning rate. Default: 0.001\n","warmup_steps = 20           #warmup_steps(int): Linear warmup step size. Default: 0\n","gamma = 1                 #gamma(float): Decrease rate of max learning rate by cycle. Default: 1.0\n","last_epoch = -1             #last_epoch (int): The index of last epoch. Default: -1\n","\n","n_epochs = 6\n","#MAX_GRADIENT = 100\n","val_train_ratio = 2\n","\n","use_cawr = False\n","\n","ACT = 8\n","\n","optimizer = optim.AdamW(model.parameters(), lr=min_lr)\n","scheduler = CosineAnnealingWarmupRestarts(optimizer,first_cycle_steps,cycle_mult,max_lr,min_lr,warmup_steps,gamma)"]},{"cell_type":"code","execution_count":19,"id":"b49ef990-76c5-48fc-acf2-7b1b51e493f3","metadata":{"id":"b49ef990-76c5-48fc-acf2-7b1b51e493f3","executionInfo":{"status":"ok","timestamp":1736824470212,"user_tz":-540,"elapsed":632,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def training(model, dataloader, criterion, optimizer, is_normal):\n","    model.train()\n","    running_loss = 0.0\n","    size = 0\n","    shift = randint(0,500)\n","    for inputs, target in tqdm(dataloader):\n","        inputs = inputs[:,:,shift:shift+500].unsqueeze(2).float().to(device)\n","        if is_normal:\n","            target = target.sum(1) > 0\n","            target = target.unsqueeze(1)\n","        target = target.float().to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, target)\n","        running_loss += loss.item()\n","        size += inputs.size(0)\n","        if np.isnan(running_loss):\n","            break\n","        loss.backward()\n","        #torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRADIENT)\n","        optimizer.step()\n","\n","    return running_loss / size"]},{"cell_type":"code","execution_count":20,"id":"46d3e613-53ee-4e25-a642-5af05363c093","metadata":{"id":"46d3e613-53ee-4e25-a642-5af05363c093","executionInfo":{"status":"ok","timestamp":1736824470862,"user_tz":-540,"elapsed":4,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def validating(model, dataloader, criterion, is_normal):\n","    model.eval()\n","    running_loss = 0.0\n","    size = 0\n","    shift = randint(0,500)\n","    with torch.no_grad():\n","        for inputs, target in tqdm(dataloader):\n","            inputs = inputs[:,:,shift:shift+500].unsqueeze(2).float().to(device)\n","            if is_normal:\n","                target = target.sum(1) > 0\n","                target = target.unsqueeze(1)\n","            target = target.float().to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, target)\n","            running_loss += loss.item()\n","            size += inputs.size(0)\n","            if np.isnan(running_loss):\n","                break\n","\n","    return running_loss / size"]},{"cell_type":"code","execution_count":21,"id":"8d542d8a-da22-4d67-a830-7cee49e0259e","metadata":{"id":"8d542d8a-da22-4d67-a830-7cee49e0259e","executionInfo":{"status":"ok","timestamp":1736824471933,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def test(model, dataloader, criterion, is_normal):\n","    model.eval()\n","    shift = randint(0,500)\n","    with torch.no_grad():\n","        for inputs, target in dataloader:\n","            #inputs, target = data[0].float().to(device), data[1].float().to(device)\n","            inputs = inputs[:,:,shift:shift+500].unsqueeze(2).float().to(device)\n","\n","            if is_normal:\n","                target = target.sum(1) > 0\n","                target = target.unsqueeze(1)\n","            target = target.float().to(device)\n","\n","            #print(target)\n","            outputs = model(inputs)\n","            outputs = torch.sigmoid(outputs)\n","            #print(torch.sigmoid(outputs))\n","            print(\"loss : \",criterion(outputs, target)/inputs.size(0))\n","            for i in range(10):\n","                print(i,\" target \",target[i])\n","                print(i,\" output \",outputs[i])\n","            break"]},{"cell_type":"code","execution_count":22,"id":"9f783429-d31a-489c-9de8-5dddc4156b48","metadata":{"id":"9f783429-d31a-489c-9de8-5dddc4156b48","executionInfo":{"status":"ok","timestamp":1736824471934,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def save_loss(loss_data, save_path):\n","    with open(save_path,\"w\") as file:\n","        for item in loss_data:\n","            file.write(\"\\n\"+str(item))"]},{"cell_type":"code","execution_count":23,"id":"6ee06cf2-47ad-4ef8-83b8-8bf0e4a7c855","metadata":{"id":"6ee06cf2-47ad-4ef8-83b8-8bf0e4a7c855","executionInfo":{"status":"ok","timestamp":1736824472454,"user_tz":-540,"elapsed":3,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def load_loss(save_path):\n","    with open(save_path,\"r\") as file:\n","        loss = file.read().split(\"\\n\")\n","        loss = [float(item) for item in loss[1:]]\n","        return loss"]},{"cell_type":"code","execution_count":24,"id":"185fffcb-3569-4292-8073-41785ecfda4f","metadata":{"id":"185fffcb-3569-4292-8073-41785ecfda4f","executionInfo":{"status":"ok","timestamp":1736824472454,"user_tz":-540,"elapsed":2,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def print_loss(train_loss, val_loss):\n","    plt.figure(figsize=(10,7))\n","    plt.plot(train_loss, color='green', label='train loss')\n","    plt.plot(list(range(val_train_ratio-1,len(train_loss),val_train_ratio)), val_loss, color='red', label='val loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":25,"id":"6d9b8f19-1f5d-4069-bc8b-c9758cd24840","metadata":{"id":"6d9b8f19-1f5d-4069-bc8b-c9758cd24840","executionInfo":{"status":"ok","timestamp":1736824472988,"user_tz":-540,"elapsed":2,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["def model_id(act):\n","    name = str(gamma_neg)+\"_\"+str(gamma_pos)+\"_\"+str(clip)+\"-\"+str(act)\n","    print(name)\n","    return name"]},{"cell_type":"code","execution_count":null,"id":"c3d64b8b-6599-41f7-add4-64bc634dafd9","metadata":{"id":"c3d64b8b-6599-41f7-add4-64bc634dafd9"},"outputs":[],"source":["# training"]},{"cell_type":"code","execution_count":31,"id":"b190d952-d57f-44b1-bf7f-47ce1132cc06","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"b190d952-d57f-44b1-bf7f-47ce1132cc06","executionInfo":{"status":"error","timestamp":1736824617882,"user_tz":-540,"elapsed":617,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"044874c8-6601-495c-a30b-4989001a394d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 / 6\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/307 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 16.81 MiB is free. Process 13201 has 39.54 GiB memory in use. Of the allocated memory 38.96 GiB is allocated by PyTorch, and 72.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-c4a16f7bd69a>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} / {n_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_normal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NAN...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-b0bd016f6cc5>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, criterion, optimizer, is_normal)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-39c8b3171f79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1152\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-b78075d115c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-c3e98e24e356>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint_wise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 16.81 MiB is free. Process 13201 has 39.54 GiB memory in use. Of the allocated memory 38.96 GiB is allocated by PyTorch, and 72.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["# single train folder training\n","train_loss_save_path = os.path.join(path,'train','train_loss_'+str(ACT)+'.txt')\n","val_loss_save_path = os.path.join(path,'train','val_loss_'+str(ACT)+'.txt')\n","min_loss_save_path = os.path.join(path,'train','min_loss_'+str(ACT)+'.txt')\n","\n","try:\n","    train_loss = load_loss(train_loss_save_path)\n","    val_loss = load_loss(val_loss_save_path)\n","    min_loss = load_loss(min_loss_save_path)[0]\n","except:\n","    train_loss = []\n","    val_loss = []\n","    min_loss = np.Inf\n","\n","start = time.time()\n","is_normal = (num_classes == 1)\n","\n","for epoch in range(n_epochs):\n","    print(f\"Epoch {epoch+1} / {n_epochs}\")\n","    epoch_loss = training(model, train_dataloader, criterion, optimizer, is_normal)\n","    if np.isnan(epoch_loss):\n","        print(\"NAN...\")\n","        break\n","    train_loss.append(epoch_loss)\n","    print(f\"Train Loss : {epoch_loss:.8f}\")\n","\n","    torch.save(model.state_dict(), os.path.join(path,'train','latest_ChkPt_'+model_id(ACT)+'.pt'))\n","\n","    if epoch % val_train_ratio == val_train_ratio - 1:\n","        epoch_loss = validating(model, test_dataloader, criterion, is_normal)\n","        if np.isnan(epoch_loss):\n","            print(\"NAN...\")\n","            break\n","        val_loss.append(epoch_loss)\n","        print(f\"Valid Loss : {epoch_loss:.8f} <<<<<<<<<<<<<<<<<<<<\")\n","        if epoch_loss < min_loss:\n","            min_loss = epoch_loss\n","            print(f\"New loss record : {min_loss:.8f} #################################################\")\n","            torch.save(model.state_dict(), os.path.join(path,'train','best_ChkPt_'+model_id(ACT)+'.pt'))\n","    if use_cawr:\n","        scheduler.step()\n","end = time.time()\n","print(f\"lowest record : {min_loss:.8f}\")\n","print(f\"Train Done > Training time : {(end-start)/60:.3f} minutes / {n_epochs} epochs\")\n","\n","save_loss(train_loss, train_loss_save_path)\n","save_loss(val_loss, val_loss_save_path)\n","save_loss([min_loss], min_loss_save_path)\n","\n","print_loss(train_loss, val_loss)"]},{"cell_type":"code","execution_count":32,"id":"eeebd3d4-022a-4ef3-9fb8-28c58e4d47ee","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"id":"eeebd3d4-022a-4ef3-9fb8-28c58e4d47ee","executionInfo":{"status":"ok","timestamp":1736821869018,"user_tz":-540,"elapsed":757,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"8ba36efc-6569-4800-a576-6986143fddaf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["train_concat = []\n","val_concat = []\n","\n","for i in range(10):\n","    if i not in [1,2,3]:\n","        try:\n","            train_concat = np.concatenate((train_concat,load_loss(os.path.join(path,'train','train_loss_'+str(i+1)+'.txt'))))\n","            val_concat = np.concatenate((val_concat,load_loss(os.path.join(path,'train','val_loss_'+str(i+1)+'.txt'))))\n","        except:\n","            break\n","\n","print_loss(train_concat, val_concat)"]},{"cell_type":"code","execution_count":47,"id":"deb76646-acd2-41b7-9b26-14266833e561","metadata":{"id":"deb76646-acd2-41b7-9b26-14266833e561","executionInfo":{"status":"ok","timestamp":1736788416279,"user_tz":-540,"elapsed":981,"user":{"displayName":"SE K","userId":"02963594443079641322"}}},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"86a4ada9-5dcf-4531-9b53-73d77884a0ba","metadata":{"id":"86a4ada9-5dcf-4531-9b53-73d77884a0ba","outputId":"39076b43-659c-4952-b89c-2c6ba240bc80"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.2_0_0-4\n"]},{"data":{"text/plain":["'0.2_0_0-4'"]},"execution_count":418,"metadata":{},"output_type":"execute_result"}],"source":["model_id(4)"]},{"cell_type":"code","execution_count":null,"id":"8bb716b4-8179-44bb-ae3d-2826c0a06461","metadata":{"id":"8bb716b4-8179-44bb-ae3d-2826c0a06461","outputId":"fdced6d6-2420-48ee-f67d-7d44a8c050f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["0_0_0-0\n"]}],"source":["torch.save(model.state_dict(), os.path.join(path,'train','ChkPt_'+model_id(0)+'.pt'))"]},{"cell_type":"code","execution_count":30,"id":"d063d1e4-614d-4852-a4f2-89c548ba57d8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d063d1e4-614d-4852-a4f2-89c548ba57d8","executionInfo":{"status":"ok","timestamp":1736824614206,"user_tz":-540,"elapsed":839,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"1c3b168e-87ea-49d4-8b41-9acbf8025cda"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":30}],"source":["model.load_state_dict(torch.load(os.path.join(path,'train','latest_ChkPt_0.2_0_0-7.pt'),weights_only=True))"]},{"cell_type":"code","execution_count":38,"id":"92d65285-de58-49dc-8707-fe0796392f3b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92d65285-de58-49dc-8707-fe0796392f3b","executionInfo":{"status":"ok","timestamp":1736790376978,"user_tz":-540,"elapsed":1032,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"f9ee3f31-26f9-41d7-bb9d-2e2f177ef892"},"outputs":[{"output_type":"stream","name":"stdout","text":["loss :  tensor(2.4278, device='cuda:0')\n","0  target  tensor([1., 1., 0., 0.], device='cuda:0')\n","0  output  tensor([0.9041, 0.4144, 0.3437, 0.0070], device='cuda:0')\n","1  target  tensor([0., 0., 1., 0.], device='cuda:0')\n","1  output  tensor([0.1233, 0.5978, 0.9077, 0.0538], device='cuda:0')\n","2  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","2  output  tensor([0.0039, 0.0235, 0.0266, 0.0084], device='cuda:0')\n","3  target  tensor([1., 0., 1., 0.], device='cuda:0')\n","3  output  tensor([0.9248, 0.0055, 0.9998, 0.0938], device='cuda:0')\n","4  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","4  output  tensor([0.0069, 0.0100, 0.1799, 0.0125], device='cuda:0')\n","5  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","5  output  tensor([0.0019, 0.0311, 0.0178, 0.0055], device='cuda:0')\n","6  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","6  output  tensor([0.0055, 0.0020, 0.0247, 0.0020], device='cuda:0')\n","7  target  tensor([0., 1., 0., 0.], device='cuda:0')\n","7  output  tensor([0.0143, 0.2590, 0.0349, 0.0045], device='cuda:0')\n","8  target  tensor([0., 0., 1., 0.], device='cuda:0')\n","8  output  tensor([0.0026, 0.0043, 1.0000, 0.1929], device='cuda:0')\n","9  target  tensor([1., 0., 0., 0.], device='cuda:0')\n","9  output  tensor([0.6008, 0.0505, 0.0534, 0.0140], device='cuda:0')\n"]}],"source":["is_normal = (num_classes == 1)\n","\n","test(model, test_dataloader, criterion, is_normal)"]},{"cell_type":"code","execution_count":39,"id":"781a9c4d-4105-4e3d-8645-c9d1f49fa10d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"781a9c4d-4105-4e3d-8645-c9d1f49fa10d","executionInfo":{"status":"ok","timestamp":1736790377534,"user_tz":-540,"elapsed":5,"user":{"displayName":"SE K","userId":"02963594443079641322"}},"outputId":"e1e25d72-d336-4a9d-c712-d865ec10324a"},"outputs":[{"output_type":"stream","name":"stdout","text":["loss :  tensor(2.4209, device='cuda:0')\n","0  target  tensor([0., 0., 1., 0.], device='cuda:0')\n","0  output  tensor([0.0097, 0.0192, 0.9998, 0.1796], device='cuda:0')\n","1  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","1  output  tensor([0.0030, 0.0012, 0.0078, 0.0014], device='cuda:0')\n","2  target  tensor([0., 0., 1., 0.], device='cuda:0')\n","2  output  tensor([0.9599, 0.0049, 0.9344, 0.0195], device='cuda:0')\n","3  target  tensor([0., 0., 1., 0.], device='cuda:0')\n","3  output  tensor([0.5066, 0.1857, 0.7991, 0.5831], device='cuda:0')\n","4  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","4  output  tensor([0.7960, 0.0162, 0.0720, 0.0156], device='cuda:0')\n","5  target  tensor([0., 1., 0., 0.], device='cuda:0')\n","5  output  tensor([0.0046, 0.7221, 0.0041, 0.0075], device='cuda:0')\n","6  target  tensor([1., 1., 1., 0.], device='cuda:0')\n","6  output  tensor([0.9939, 0.3104, 0.5453, 0.0308], device='cuda:0')\n","7  target  tensor([1., 0., 0., 0.], device='cuda:0')\n","7  output  tensor([0.9536, 0.0195, 0.0366, 0.0170], device='cuda:0')\n","8  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","8  output  tensor([0.0058, 0.0411, 0.0275, 0.0085], device='cuda:0')\n","9  target  tensor([0., 0., 0., 0.], device='cuda:0')\n","9  output  tensor([0.0021, 0.0020, 0.0163, 0.0015], device='cuda:0')\n"]}],"source":["is_normal = (num_classes == 1)\n","\n","test(model, train_dataloader, criterion, is_normal)"]},{"cell_type":"code","execution_count":null,"id":"a5e6c837-0062-4171-afde-f8184e36c968","metadata":{"id":"a5e6c837-0062-4171-afde-f8184e36c968"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}